[Near Critical Disk Usage]
alert.track = 0
description = Display instances where the disk capacity exceeds 80%. Uses the /services/server/status/partitions-space REST endpoint. [health,disk,internal]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = | rest splunk_server_group=dmc_group_* /services/server/status/partitions-space \
| eval free = if(isnotnull(available), available, free) \
| eval usage = capacity - free \
| eval pct_usage = floor(usage / capacity * 100) \
| where pct_usage > 80 \
| stats first(fs_type) as fs_type first(capacity) AS capacity first(usage) AS usage first(pct_usage) AS pct_usage by splunk_server, mount_point \
| eval usage = round(usage / 1024, 2) \
| eval capacity = round(capacity / 1024, 2) \
| rename splunk_server AS Instance mount_point as "Mount Point", fs_type as "File System Type", usage as "Usage (GB)", capacity as "Capacity (GB)", pct_usage as "Usage (%)"

[Saturated Event-Processing Queues]
alert.track = 0
description = Display indexer queues where a fill percentage, averaged over the last 15 minutes, exceeds 90%. Uses the /services/server/status/partitions-space REST endpoint. [health,indexing,internal]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = | rest splunk_server_group=dmc_group_* /services/server/status/partitions-space \
| eval free = if(isnotnull(available), available, free) \
| eval usage = capacity - free \
| eval pct_usage = floor(usage / capacity * 100) \
| where pct_usage > 80 \
| stats first(fs_type) as fs_type first(capacity) AS capacity first(usage) AS usage first(pct_usage) AS pct_usage by splunk_server, mount_point \
| eval usage = round(usage / 1024, 2) \
| eval capacity = round(capacity / 1024, 2) \
| rename splunk_server AS Instance mount_point as "Mount Point", fs_type as "File System Type", usage as "Usage (GB)", capacity as "Capacity (GB)", pct_usage as "Usage (%)"

[Scheduled Search Distribution]
action.email.useNSSubject = 1
alert.track = 0
description = Displays the distribution of scheduled searches over time. Ideally, scheduled searches should be distributed as evenly as possible. [internal,informational,search]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal sourcetype=scheduler status=success OR status=skipped\
| dedup scheduled_time savedsearch_name\
| eval _time=scheduled_time\
| timechart count span=1m\
| search count > 10

[Search Range and Frequency Mismatch]
action.email.useNSSubject = 1
alert.track = 0
description = Displays scheduled searches where the search range is longer than the scheduled frequency of those searches, which leads to an overlap in results. In some cases an overlap may be appropriate depending on the use case. [internal,health,search]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = | rest /services/saved/searches \
| where is_scheduled=1 \
| table search schedule_window schedule_priority title cron_schedule dispatch.earliest_time dispatch.latest_time\
| rename dispatch.* as *\
| rex field=cron_schedule "(?<min>\S+)\s(?<hour>\S+)\s(?<day_month>\S+)\s(?<month>\S+)\s(?<day_week>\S+)"\
| eval min=if(isnum(min), min, -1), hour=if(isnum(hour), hour, -1), day_month=if(isnum(day_month), day_month, -1), month=if(isnum(month), month, -1), day_week=if(isnum(day_week), day_week, -1)\
| search (earliest_time=*mon* day_month=-1) OR (earliest_time=*d* earliest_time!=*1d* day_week=-1) OR (earliest_time=*h* min=-1)\
| table title cron_schedule earliest_time latest_time\
| rename title as Name cron_schedule as Schedule earliest_time as "Earliest Time" latest_time as "Latest Time"

[Searches with Long Run Times]
action.email.useNSSubject = 1
alert.track = 0
description = Displays scheduled searches with an average run time (the time taken to complete the search) of 30 minutes or longer. [internal,health,search]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal sourcetype=scheduler status=success \
| stats avg(run_time) as run_time by savedsearch_name\
| eval run_time=run_time/3600\
| where run_time>0.5\
| rename savedsearch_name as Name run_time as "Run Time (Hours)"

[Server Ulimit Assessment]
action.email.useNSSubject = 1
alert.track = 0
description = Checks and displays instances that are not provisioned with ulimit settings (file descriptors, user processes, and data segment size) that are adequate for running Splunk software.[internal,health]
dispatch.earliest_time = 0
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal component=ulimit sourcetype=splunkd \
| search "data segment size" OR "open files" OR "user processes" \
| rex field=event_message "Limit: (?<ulimit>[^:]+): (?<size>\d+|unlimited)" \
| eval recommended = case(ulimit="data segment size","unlimited",ulimit="open files",64000,ulimit="user processes",16000) \
| eval good=if(size >= recommended OR size="unlimited",1,0)\
| eventstats min(good) as good by host\
| search good=0\
| eval size=size." / ".recommended\
| eval ulimit = ulimit." (current / recommended)"\
| chart latest(size) over host by ulimit\
| rename ulimit as Ulimit

[Skipped Searches]
action.email.useNSSubject = 1
alert.track = 0
description = Displays scheduled searches with a skipped percentage of 25% or higher. [internal,health,search]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal sourcetype=scheduler status="success" OR status="skipped" \
| dedup scheduled_time savedsearch_name\
| stats count as total count(eval(status="skipped")) as skipped by savedsearch_name\
| eval perc=skipped/total*100\
| search perc > 25\
| sort -perc\
| rename savedsearch_name as Name total as Total skipped as Skipped perc as %

[Total License Usage Near Daily Quota]
alert.track = 0
description = Display instances where the license usage exceeds 90% of your total daily license quota. Uses the /services/licenser/pools REST endpoint. [health,license,internal]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = | rest splunk_server_group=dmc_group_license_master /services/licenser/pools \
| join type=outer stack_id splunk_server [rest splunk_server_group=dmc_group_license_master /services/licenser/groups | search is_active=1 | eval stack_id=stack_ids | fields splunk_server stack_id is_active] \
| search is_active=1 \
| fields splunk_server, stack_id, used_bytes \
| join type=outer stack_id splunk_server [rest splunk_server_group=dmc_group_license_master /services/licenser/stacks | eval stack_id=title | eval stack_quota=quota | fields splunk_server stack_id stack_quota] \
| stats sum(used_bytes) as used_bytes max(stack_quota) as stack_quota by splunk_server \
| eval usedGB=round(used_bytes/1024/1024/1024,3) \
| eval totalGB=round(stack_quota/1024/1024/1024,3) \
| eval percentage=round(usedGB / totalGB, 3)*100 \
| fields splunk_server, percentage, usedGB, totalGB \
| where percentage > 90 \
| rename splunk_server AS Instance, percentage AS "License quota used (%)", usedGB AS "License quota used (GB)", totalGB as "Total license quota (GB)"

[Forwarder Version]
alert.track = 0
description = Displays the percentage of forwarders, that have phoned home at least once within the given time interval, by version, type, and operating system. For additional information on compatibility between forwarders and Splunk Enterprise indexers, visit https://docs.splunk.com/Documentation/VersionCompatibility/current/Matrix/Compatibilitybetweenforwardersandindexers [informational,internal,forwarder]
dispatch.earliest_time = -7d@d
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal sourcetype=splunkd group=tcpin_connections version=* os=* arch=* build=* hostname=* source=*metrics.log\
| stats latest(version) as version latest(os) as os latest(fwdType) as fwdType by hostname\
| top version by os fwdType\
| rename os as OS fwdType as "Forwarder Type" version as Version count as Count percent as %

[List Correlation Searches]
action.email.useNSSubject = 1
alert.track = 0
description = Displays the app, security domain, name, and description of all enabled correlation searches in your environment. Uses the /services/saved/searches REST endpoint. For additional information on this REST endpoint, visit https://docs.splunk.com/Documentation/Splunk/latest/RESTREF/RESTsearch [internal,informational,ES]
display.general.timeRangePicker.show = 0
search = | rest splunk_server=local count=0 /services/saved/searches | where match('action.correlationsearch.enabled', "1|[Tt]|[Tt][Rr][Uu][Ee]") | rename eai:acl.app as app, title as csearch_name, action.correlationsearch.label as csearch_label, action.notable.param.security_domain as security_domain | table csearch_name, csearch_label, app, security_domain, description

[Unsecured Communication]
alert.track = 0
description = Displays instances where network traffic is not protected by the secure socket layer (SSL) protocol by host name and destination port. [security,internal,health]
dispatch.earliest_time = -4h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal component=Metrics group=tcpin_connections ssl=false\
| stats latest(sourceIp) as "Source IP" by hostname ssl destPort\
| rename hostname as Hostname ssl as SSL destPort as "Destination Port"

[Users with Delete Capabilities]
action.email.useNSSubject = 1
alert.track = 0
description = Displays users with the "delete_by_keyword" capability which allows them to prevent data from being returned during a search. Ideally, this capability should not be enabled for any user in a production environment. For additional information on Splunk capabilities visit https://docs.splunk.com/Documentation/Splunk/Latest/Security/Rolesandcapabilities [internal,health,users]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = | rest /services/authentication/users\
| search capabilities=delete_by_keyword\
| table title type realname email roles splunk_server

[Local Accounts]
action.email.useNSSubject = 1
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Displays all local accounts that exist within your environment. [health,informational,internal,users]
display.general.timeRangePicker.show = 0
search = | rest /services/authentication/users \
| search type=Splunk\
| table title type realname email roles splunk_server

[Critical System Physical Memory Usage]
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Displays all instances that have exceeded 90% memory usage. Uses the /services/server/status/resource-usage/hostwide REST endpoint. For additional information on this REST endpoint, visit https://docs.splunk.com/Documentation/Splunk/latest/RESTREF/RESTsystem [memory,health,internal]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = | rest splunk_server_group=dmc_group_* /services/server/status/resource-usage/hostwide \
| eval percentage=round(mem_used/mem,3)*100 \
| where percentage > 90 \
| fields splunk_server, percentage, mem_used, mem \
| rename splunk_server AS Instance, mem AS "Physical memory installed (MB)", percentage AS "Memory used (%)", mem_used AS "Memory used (MB)"

[Expired or Soon to Expire License]
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Display licenses that expired or will expire within 2 weeks. Uses the /services/licenser/licenses REST endpoint. For additional information on this REST endpoint, visit https://docs.splunk.com/Documentation/Splunk/latest/RESTREF/RESTlicense. To learn more about Splunk licenses and license violations, visit https://docs.splunk.com/Documentation/Splunk/latest/Admin/Aboutlicenseviolations [health,license,internal]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = | rest splunk_server_group=dmc_group_license_master /services/licenser/licenses \
| join type=outer group_id splunk_server [ \
    rest splunk_server_group=dmc_group_license_master /services/licenser/groups \
    | where is_active = 1 \
    | rename title AS group_id \
    | fields is_active group_id splunk_server] \
| where is_active = 1 \
| eval days_left = floor((expiration_time - now()) / 86400)  \
| where (status == "EXPIRED" OR days_left < 15) AND NOT (quota = 1048576 OR label == "Splunk Enterprise Reset Warnings" OR label == "Splunk Lite Reset Warnings") \
| eval expiration_status = case(days_left >= 14, days_left." days left", days_left < 14 AND days_left >= 0, "Expires soon: ".days_left." days left", days_left < 0, "Expired") \
| eval total_gb=round(quota/1024/1024/1024,3) \
| fields splunk_server label license_hash type group_id total_gb expiration_time expiration_status \
| convert ctime(expiration_time) \
| rename splunk_server AS Instance label AS "Label" license_hash AS "License Hash" type AS Type group_id AS Group total_gb AS Size expiration_time AS "Expires On" expiration_status AS Status

[Admin Login Attempts]
action.email.useNSSubject = 1
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Displays the login attempts of the local admin account by source, destination, and status. [internal,informational,users]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_audit action="login attempt" user="admin" \
| stats count earliest(_time) as earliest latest(_time) as latest by src host info \
| sort info -count\
| rename src as Source host as Destination info as Status count as Count earliest as Earliest latest as Latest\
| fieldformat Earliest=strftime(Earliest, "%F %T") \
| fieldformat Latest=strftime(Latest, "%F %T")

[Data Quality Issues]
action.email.useNSSubject = 1
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Displays the count of aggregation, line breaking, and date parsing issues per sourcetype. For additional information and descriptions of these issues, visit https://docs.splunk.com/Documentation/Splunk/latest/Data/Resolvedataqualityissues [internal,health]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal (source=*splunkd.log* (component=AggregatorMiningProcessor OR component= LineBreakingProcessor OR component=DateParserVerbose) (log_level=WARN OR log_level=ERROR))\
| rex field=event_message "Context\: source\=[^\|]+\|host=(?<data_host2>[^\|]+)\|(?<data_sourcetype2>[^\|]+)\|"\
| eval sourcetype=coalesce(data_sourcetype, data_sourcetype2)\
| eval host=coalesce(data_host, data_host2)\
| stats count(eval(component=="AggregatorMiningProcessor")) AS aggregation_issues count(eval(component=="LineBreakingProcessor")) AS line_breaking_issues count(eval(component=="DateParserVerbose")) AS date_parsing_issues by sourcetype\
| eval total = aggregation_issues+line_breaking_issues+date_parsing_issues\
| sort -total

[Daily License Usage]
action.email.useNSSubject = 1
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Displays a chart of the daily license usage in gigabytes (GB) over the last 30 days. To learn more about Splunk licenses and license violations, visit https://docs.splunk.com/Documentation/Splunk/latest/Admin/Aboutlicenseviolations [internal,informational,license]
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = visualizations
display.page.search.tab = visualizations
display.statistics.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal source=*license_usage* type=RolloverSummary \
| bucket _time span=1d \
| eval GB_vol=b/1024/1024/1024 \
| timechart span=1d sum(GB_vol) as "Usage (GB)"

[Linux Kernel Transparent Huge Pages (THP)]
action.email.useNSSubject = 1
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Displays instances that are running on a host that has kernel transparent huge pages (THP) enabled. This can significantly reduce performance and is against best practice. This check is relevant only for Linux. For additional information, visit https://docs.splunk.com/Documentation/Splunk/latest/ReleaseNotes/SplunkandTHP [internal,health]
dispatch.earliest_time = 0
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal component=ulimit transparent\
| dedup host enabled defrag\
| search enabled=always OR defrag=always\
| table host enabled defrag\
| rename host as Host enabled as Enabled defrag as Defrag

[Indexing Latency]
action.email.useNSSubject = 1
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Displays the minimum, maximum, and average indexing latency for each index. The indexing latency is defined as the amount of time between when an event is generated as noted by its _time value and when it is indexed as noted by its _indextime value. [internal,health,indexing]
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = visualizations
display.page.search.tab = visualizations
display.statistics.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = | tstats prestats=true count where index=* by _time,_indextime,host,sourcetype,index span=1s \
| eval latency=abs(_indextime-_time)/3600\
| search latency > 1\
| fields - psrsvd* \
| stats avg(latency) as avg_latency min(latency) as min_latency max(latency) as max_latency count by host\
| sort -avg_latency\
| rename host as Host avg_latency as "Avg. Latency (Hours)" max_latency as "Max. Latency (Hours)" min_latency as "Min. Latency (Hours)" count as "Event Count"

[Forwarders Phoning Home Too Frequently]
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Displays forwarders where the average phone home interval is less than 5 minutes. The phone home interval is calculated by taking at least 10 phone home messages per forwarder and averaging the time interval between them. [internal,health]
dispatch.earliest_time = -4h@h
dispatch.latest_time = now
display.general.timeRangePicker.show = 0
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = index=_internal source=*splunkd.log "running phone" \
| stats count min(_time) as min_time max(_time) as max_time by host \
| search count >= 10\
| eval span=max_time-min_time, sec_per_phone=span/count \
| search sec_per_phone<300\
| fields host count sec_per_phone\
| sort sec_per_phone asc\
| rename host as Host count as Count sec_per_phone as "Phone Home Interval (sec.)"

[Orphaned Scheduled Searches]
action.email.useNSSubject = 1
action.triggr = 0
action.triggr.param.targets = []
alert.track = 0
description = Displays scheduled searches whose owners no longer exist within Splunk. The search scheduler cannot run a scheduled report on behalf of a nonexistent owner. Uses the /servicesNS/-/-/saved/searches REST endpoint. For additional information on this REST endpoint visit, https://docs.splunk.com/Documentation/Splunk/8.0.0/RESTREF/RESTsearch. For additional information on orphaned searches, visit https://docs.splunk.com/Documentation/Splunk/latest/Knowledge/Resolveorphanedsearches [internal,health]
dispatch.earliest_time = -24h@h
dispatch.latest_time = now
display.general.type = statistics
display.page.search.tab = statistics
display.visualizations.show = 0
request.ui_dispatch_app = searchdict
request.ui_dispatch_view = search
search = | rest splunk_server=local /servicesNS/-/-/saved/searches add_orphan_field=yes count=0 \
| where disabled=0 AND is_scheduled=1 AND orphan=1\
| table title eai:acl.app eai:acl.owner\
| rename eai:acl.app as App eai:acl.owner as Owner title as Name
